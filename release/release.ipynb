{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 发布\n",
    "> 将文件打包，上传到github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "!pip install nbdev -U\n",
    "!nbdev_install_git_hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting: /Users/Neo/crawler_from_scratch/02_Crawler_Sample.ipynb\n",
      "converting: /Users/Neo/crawler_from_scratch/11_Proxy_Request.ipynb\n",
      "converting: /Users/Neo/crawler_from_scratch/01_Advanced_Request.ipynb\n",
      "An error occurred while executing the following cell:\n",
      "------------------\n",
      "#export\n",
      "from nbdev.showdoc import show_doc\n",
      "from crawler_from_scratch.proxy import *\n",
      "------------------\n",
      "\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-1-ca2e9dca9d51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[0;31m#export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnbdev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowdoc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_doc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcrawler_from_scratch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'crawler_from_scratch'\n",
      "ModuleNotFoundError: No module named 'crawler_from_scratch'\n",
      "\n",
      "An error occurred while executing the following cell:\n",
      "------------------\n",
      "#export\n",
      "from nbdev.showdoc import show_doc\n",
      "from crawler_from_scratch.utils import *\n",
      "------------------\n",
      "\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-1-5e79759f3933>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[0;31m#export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnbdev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowdoc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_doc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcrawler_from_scratch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'crawler_from_scratch'\n",
      "ModuleNotFoundError: No module named 'crawler_from_scratch'\n",
      "\n",
      "An error occurred while executing the following cell:\n",
      "------------------\n",
      "# export\n",
      "%reload_ext autoreload\n",
      "%autoreload 2\n",
      "import pandas as pd\n",
      "import requests,json,re\n",
      "from bs4 import BeautifulSoup,Tag,NavigableString\n",
      "from collections import Counter\n",
      "from crawler_from_scratch.utils import *\n",
      "------------------\n",
      "\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-1-e3f203f26090>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNavigableString\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcrawler_from_scratch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'crawler_from_scratch'\n",
      "ModuleNotFoundError: No module named 'crawler_from_scratch'\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/bin/nbdev_build_docs\", line 10, in <module>\n",
      "    sys.exit(nbdev_build_docs())\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/fastscript/core.py\", line 73, in _f\n",
      "    func(**args.__dict__)\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/nbdev/cli.py\", line 101, in nbdev_build_docs\n",
      "    notebook2html(fname=fname, force_all=force_all, n_workers=n_workers)\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/nbdev/export2html.py\", line 436, in notebook2html\n",
      "    raise Exception(msg + '\\n'.join([f.name for p,f in zip(passed,files) if not p]))\n",
      "Exception: Conversion failed on the following:\n",
      "01_Advanced_Request.ipynb\n",
      "02_Crawler_Sample.ipynb\n",
      "11_Proxy_Request.ipynb\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# !nbdev_build_lib\n",
    "!nbdev_build_docs\n",
    "# !nbdev_test_nbs --fname 11_Proxy_Request.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\r\n",
      "Your branch is up to date with 'origin/master'.\r\n",
      "\r\n",
      "Changes not staged for commit:\r\n",
      "  (use \"git add <file>...\" to update what will be committed)\r\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\r\n",
      "\r\n",
      "\t\u001b[31mmodified:   00_Getting_Started.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   01_Advanced_Request.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   data/01_douban.json\u001b[m\r\n",
      "\t\u001b[31mmodified:   index.ipynb\u001b[m\r\n",
      "\r\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\r\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 0a5ede2] finish proxy request\n",
      " 13 files changed, 3244 insertions(+), 147 deletions(-)\n",
      " create mode 100644 02_Crawler_Sample.ipynb\n",
      " delete mode 100644 02_auto_crawler.ipynb\n",
      " create mode 100644 11_Proxy_Request.ipynb\n",
      " rewrite data/01_douban.json (100%)\n",
      " create mode 100644 data/02_bilibili.json\n",
      " create mode 100644 data/11_Proxy.json\n",
      " create mode 100644 data/log\n",
      " create mode 100644 release/others.ipynb\n",
      " rename publish.ipynb => release/release.ipynb (88%)\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# 除了变化的文件，新增的文件也加进去\n",
    "!git add -A\n",
    "# add变化的文件和commit合成一条\n",
    "!git commit -m \"finish proxy request\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "Enumerating objects: 33, done.\n",
      "Counting objects: 100% (33/33), done.\n",
      "Delta compression using up to 4 threads\n",
      "Compressing objects: 100% (17/17), done.\n",
      "Writing objects: 100% (18/18), 13.67 KiB | 4.56 MiB/s, done.\n",
      "Total 18 (delta 14), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (14/14), completed with 13 local objects.\u001b[K\n",
      "To https://github.com/neo4dev/crawler_from_scratch.git\n",
      "   8688d99..2fb82a1  master -> master\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "!git pull\n",
    "# 第一次push需要用户名密码，可能需要在terminal输入\n",
    "# 因为国内push总超时，这是用shadowsocks代理的方法\n",
    "!git config --global http.https://github.com.proxy socks5://127.0.0.1:1086\n",
    "!git config --global https.https://github.com.proxy socks5://127.0.0.1:1086\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

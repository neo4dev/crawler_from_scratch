{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MongoDB简介\n",
    "[官网](https://www.mongodb.com/) | [文档入口](https://docs.mongodb.com/) | [MongoDB Python Drivers文档](https://docs.mongodb.com/ecosystem/drivers/python/) | [MongoDB 大学](https://university.mongodb.com/courses/M001/about)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安装\n",
    "\n",
    "1. 下载[MongoDB Server](https://www.runoob.com/mongodb/mongodb-osx-install.html) | [PyMongo](https://www.runoob.com/python3/python-mongodb.html)\n",
    "* 先创建数据存储地址 `mkdir -p ./data/db`\n",
    "* 再启动 mongo 服务端 `mongod --dbpath=./data/db`\n",
    "* 最后`import pymongo` 就可以操作了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概念\n",
    "数据结构\n",
    "* Databases 数据库\n",
    "* Collections 表\n",
    "* Documents JSON格式的数据\n",
    "\n",
    "数据操作\n",
    "* CRUD (Create Read Update Delete) 增删改查 \n",
    "\n",
    "工具\n",
    "* MongoDB Atlas 云服务\n",
    "* MongoDB Compass 数据管理客户端"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据操作\n",
    "[PyMongo文档](https://pymongo.readthedocs.io/en/stable/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient,DESCENDING\n",
    "client = MongoClient('mongodb://127.0.0.1:27017')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 新增"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client.test_db\n",
    "users = db.users\n",
    "result = users.insert_one({'name':'hawk'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.inserted_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.list_database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in users.find({'name': 'hawk'}):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 计数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.count_documents({'name': 'hawk'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in users.find().sort('_id', DESCENDING):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 其他"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in users.find().sort('_id', DESCENDING).skip(1).limit(2):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.delete_one({'name':'hawk'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.drop_collection('users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.drop_database('test_db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 修改\n",
    "[Update Operator文档](https://docs.mongodb.com/manual/reference/operator/update/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.update_one({'name':'hawk'},{'$set':{'age':30}})\n",
    "users.update_one({'age':30},{'$inc':{'age':2}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in users.find():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 筛选条件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<table><thead><tr><th>符号</th><th>含义</th><th>示例</th></tr></thead><tbody><tr><td><code>$lt</code></td><td>小于</td><td><code>{'age': {'$lt': 20}}</code></td></tr><tr><td><code>$gt</code></td><td>大于</td><td><code>{'age': {'$gt': 20}}</code></td></tr><tr><td><code>$lte</code></td><td>小于等于</td><td><code>{'age': {'$lte': 20}}</code></td></tr><tr><td><code>$gte</code></td><td>大于等于</td><td><code>{'age': {'$gte': 20}}</code></td></tr><tr><td><code>$ne</code></td><td>不等于</td><td><code>{'age': {'$ne': 20}}</code></td></tr><tr><td><code>$in</code></td><td>在范围内</td><td><code>{'age': {'$in': [20, 23]}}</code></td></tr><tr><td><code>$nin</code></td><td>不在范围内</td><td><code>{'age': {'$nin': [20, 23]}}</code></td></tr></tbody></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<table><thead><tr><th>符号</th><th>含义</th><th>示例</th><th>示例含义</th></tr></thead><tbody><tr><td><code>$regex</code></td><td>匹配正则表达式</td><td><code>{'name': {'$regex': '^M.*'}}</code></td><td><code>name</code>以M开头</td></tr><tr><td><code>$exists</code></td><td>属性是否存在</td><td><code>{'name': {'$exists': True}}</code></td><td><code>name</code>属性存在</td></tr><tr><td><code>$type</code></td><td>类型判断</td><td><code>{'age': {'$type': 'int'}}</code></td><td><code>age</code>的类型为<code>int</code></td></tr><tr><td><code>$mod</code></td><td>数字模操作</td><td><code>{'age': {'$mod': [5, 0]}}</code></td><td>年龄模5余0</td></tr><tr><td><code>$text</code></td><td>文本查询</td><td><code>{'$text': {'$search': 'Mike'}}</code></td><td><code>text</code>类型的属性中包含<code>Mike</code>字符串</td></tr><tr><td><code>$where</code></td><td>高级条件查询</td><td><code>{'$where': 'obj.fans_count == obj.follows_count'}</code></td><td>自身粉丝数等于关注数</td></tr></tbody></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "详细规则 https://docs.mongodb.com/manual/reference/operator/query/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_one_and_delete\n",
    "# find_one_and_replace\n",
    "users.find_one_and_update({'age':32},{'$inc':{'age':2}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实践案例，爬人人都是产品经理网站\n",
    "> MongoDB的存储位置为./data/db\n",
    "\n",
    "现存问题：\n",
    "- [x] 爬取url太慢：用代理并行去爬\n",
    "- [ ] 爬url，经常overtry，因为网站经常会卡死，设定workers少一点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp RRPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import requests,re,time,sys\n",
    "from bs4 import BeautifulSoup\n",
    "from crawler_from_scratch import IpPool\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "client = MongoClient('mongodb://127.0.0.1:27017')\n",
    "db = client.crawler\n",
    "art_coll = db.articals\n",
    "\n",
    "category = 'pd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def simple_request(url) -> object:\n",
    "    res = requests.get(url,headers={'user-agent':'Mozilla/5.0'})\n",
    "    soup = BeautifulSoup(res.text)\n",
    "    return soup.body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成待爬url list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def crawl_artical_url_v1(category_page_url) -> iter:\n",
    "    res = requests.get(category_page_url)\n",
    "    soup = BeautifulSoup(res.text,features='lxml').body\n",
    "    for s in soup.find_all('h2','post-title'):\n",
    "        url = s.a['href']\n",
    "        if 'woshipm' in url: yield url\n",
    "    \n",
    "def get_urls_v1(start,end) -> list:\n",
    "    global category\n",
    "    urls = []\n",
    "    category_url = f'http://www.woshipm.com/category/{category}'\n",
    "    for i in range(start,end+1):\n",
    "        page_url = f'{category_url}/page/{i}'\n",
    "        print(page_url)\n",
    "        for url in crawl_artical_url_v1(page_url):\n",
    "            urls.append(url)\n",
    "    print('urls:',len(urls),'per_page:',len(urls)/(end-start+1))\n",
    "    urls = list(set(urls))\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_urls_v1(20,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def crawl_artical_url(category_page_url) -> list:\n",
    "    urls = []\n",
    "    res = IpPool.proxy_get(category_page_url)\n",
    "    soup = BeautifulSoup(res.text,features='lxml').body\n",
    "    for s in soup.find_all('h2','post-title'):\n",
    "        url = s.a['href']\n",
    "        if 'woshipm' in url: urls.append(url)\n",
    "    \n",
    "    # 获取失败的情况\n",
    "    if len(urls) == 0: \n",
    "        print('\\n\\n!no urls:',category_page_url, 'retrying......')\n",
    "        urls = crawl_artical_url(category_page_url)\n",
    "    print('crawl urls:',category_page_url,'got:',len(urls))\n",
    "    return urls\n",
    "\n",
    "def parallel_crawl_artical_url(start,end) -> list:\n",
    "    global category\n",
    "    urls = []\n",
    "    page_urls = [f'http://www.woshipm.com/category/{category}/page/{i}' for i in range(start,end+1)]\n",
    "    for data in IpPool.parallel_task(crawl_artical_url,page_urls,10):\n",
    "        urls += data\n",
    "    urls = list(set(urls))\n",
    "    print('urls:',len(urls))\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.7yip.cn/free/ 新增：0，库存更新为：2122个\n",
      "http://www.ip3366.net/free/ 新增：4，库存更新为：2126个\n",
      "http://www.nimadaili.com/gaoni/ 新增：37，库存更新为：2163个\n",
      "http://www.xiladaili.com/gaoni/ 新增：3，库存更新为：2166个\n",
      "https://www.kuaidaili.com/free/inha/ 新增：0，库存更新为：2167个\n",
      "https://ip.jiangxianli.com/?anonymity=2 新增：7，库存更新为：2173个\n",
      "http://proxyslist.com/ 新增：23，库存更新为：2196个\n",
      "https://list.proxylistplus.com/Fresh-HTTP-Proxy-List-1 新增：1，库存更新为：2197个\n",
      "移除： 0 个IP\n",
      "success: http://www.woshipm.com/category/it/page/2 try times: 1\n",
      "crawl urls: http://www.woshipm.com/category/it/page/2 got: 12\n"
     ]
    }
   ],
   "source": [
    "crawl_artical_url('http://www.woshipm.com/category/it/page/2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'it'\n",
    "urls = parallel_crawl_artical_url(1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.woshipm.com/it/3690544.html',\n",
       " 'http://www.woshipm.com/it/3690303.html',\n",
       " 'http://www.woshipm.com/it/3679467.html',\n",
       " 'http://www.woshipm.com/it/3689204.html',\n",
       " 'http://www.woshipm.com/it/3688145.html',\n",
       " 'http://www.woshipm.com/it/3658393.html',\n",
       " 'http://www.woshipm.com/it/3685361.html',\n",
       " 'http://www.woshipm.com/it/3685687.html',\n",
       " 'http://www.woshipm.com/it/3684275.html',\n",
       " 'http://www.woshipm.com/it/3679947.html',\n",
       " 'http://www.woshipm.com/it/3684034.html',\n",
       " 'http://www.woshipm.com/it/3678488.html',\n",
       " 'http://www.woshipm.com/it/3678488.html',\n",
       " 'http://www.woshipm.com/it/3686449.html',\n",
       " 'http://www.woshipm.com/it/3686307.html',\n",
       " 'http://www.woshipm.com/it/3683307.html',\n",
       " 'http://www.woshipm.com/it/3679936.html',\n",
       " 'http://www.woshipm.com/it/3684661.html',\n",
       " 'http://www.woshipm.com/it/3682891.html',\n",
       " 'http://www.woshipm.com/it/3678595.html',\n",
       " 'http://www.woshipm.com/it/3678962.html',\n",
       " 'http://www.woshipm.com/it/3677359.html',\n",
       " 'http://www.woshipm.com/it/3677782.html',\n",
       " 'http://www.woshipm.com/it/3679192.html']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代理访问&保存html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def save_artical(response) -> int:\n",
    "    global category\n",
    "    url = response.url\n",
    "    _id = int(re.search(r'\\d+',url).group())\n",
    "    \n",
    "    soup = BeautifulSoup(response.text,features='lxml')\n",
    "    content = str(soup.find('div','single-wrapper'))\n",
    "\n",
    "    try:\n",
    "        artical = art_coll.insert_one({'_id':_id,\n",
    "                                       'category':category,\n",
    "                                       'url':url,\n",
    "                                       'html':content})\n",
    "        return artical.inserted_id\n",
    "    except:\n",
    "        print('\\n\\n!error',url,sys.exc_info())\n",
    "    \n",
    "def crawl_artical(url):\n",
    "    global category,art_coll\n",
    "    _id = int(re.search(r'\\d+',url).group())\n",
    "    \n",
    "    # 爬过，则结束\n",
    "    if art_coll.find_one({'_id':_id}):\n",
    "        print('exist:',url)\n",
    "        return\n",
    "    \n",
    "    # 重复爬10次，直到res=200，不然就log\n",
    "    res = IpPool.proxy_get(url) \n",
    "    if res: save_artical(res)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exist: http://www.woshipm.com/rp/3660512.html\n"
     ]
    }
   ],
   "source": [
    "crawl_artical('http://www.woshipm.com/rp/3660512.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 批量操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def crawl_artical_url_and_html(category_page_url):\n",
    "    urls = crawl_artical_url(category_page_url)\n",
    "    IpPool.parallel_task(crawl_artical,urls,10,False)\n",
    "    print('complete:',category_page_url)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def crawl_artical_by_category():\n",
    "    global category\n",
    "    category = 'blockchain'\n",
    "    start,end = 1,20\n",
    "    category_page_urls = [f'http://www.woshipm.com/category/{category}/page/{i}' for i in range(start,end+1)]\n",
    "    IpPool.parallel_task(crawl_artical_url_and_html,category_page_urls,20)\n",
    "#     urls = parallel_crawl_artical_url(1,133)    \n",
    "# #     urls = get_urls_v1(1,257)\n",
    "#     IpPool.parallel_task(crawl_artical,urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完善数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_no_html() -> list:\n",
    "    no_html_urls = []\n",
    "#     for a in art_coll.find({'html':{'$exists':True},'$where':\"(this.html.length < 100)\"}):\n",
    "    for a in art_coll.find({'html':{'$exists':False}}):\n",
    "        no_html_urls.append(a['url'])\n",
    "    print(len(no_html_urls))\n",
    "    return no_html_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_html(url):\n",
    "    res = IpPool.proxy_get(url)\n",
    "    soup = BeautifulSoup(res.text,features='lxml')\n",
    "    content = str(soup.find('div','single-wrapper'))\n",
    "    result = art_coll.update_one({'url':url},{'$set':{'html':content}})\n",
    "    print('update:',url,result.modified_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_no_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IpPool.parallel_task(update_html,check_no_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解析内容字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parse_ymd(s):\n",
    "    year_s, mon_s, day_s = s.split('-')\n",
    "    return datetime(int(year_s), int(mon_s), int(day_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parse_html(_id=3614430) -> object:\n",
    "    update_content = {}\n",
    "    try:\n",
    "        soup = BeautifulSoup(art_coll.find_one({'_id':_id})['html'],features='lxml')\n",
    "        update_content['title'] = soup.h2.text\n",
    "        author_soup = soup.find('div','postMetaLockup--authorWithBio u-flex')\n",
    "        update_content['author_link'] = author_soup.a['href']\n",
    "\n",
    "        author_info = [s for s in author_soup.stripped_strings]\n",
    "        update_content['author_name'] = author_info[0]\n",
    "        update_content['likes'] = int(author_info[-1])\n",
    "        update_content['stars'] = int(author_info[-2])\n",
    "        update_content['views'] = int(author_info[-3])\n",
    "        update_content['publish_date'] = parse_ymd(author_info[-4])\n",
    "        update_content['tags'] = [a.text for a in soup.find('div','taglist')] if soup.find('div','taglist') else []\n",
    "    except:\n",
    "        print('parse error:',_id)\n",
    "    return update_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def update_artical_info(_id) -> int: \n",
    "    result = art_coll.update_one({'_id':_id},{'$set':parse_html(_id)})\n",
    "    return result.modified_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse error: 1633891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'title': '如何报名'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_html(1633891)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_artical_info(3614430)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# http://www.woshipm.com/it/793639.html\n",
    "# http://www.woshipm.com/it/1633891.html\n",
    "# 这两个是培训课程，需删掉\n",
    "def update_all_artical_info():\n",
    "    ids = [i['_id'] for i in art_coll.find({'likes':{'$exists':False}})]\n",
    "    task_results = IpPool.parallel_task(update_artical_info,ids,1)\n",
    "    modify_count = len([i for i in task_results if i> 0])\n",
    "    print('modify:',modify_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检查数据完整性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def correct_field_type(_id=3614430):\n",
    "    art = art_coll.find_one({'_id':_id})\n",
    "    if type(art['views']) == str:\n",
    "        if '万' in art['views']:\n",
    "            art['views'] = float(art['views'].replace('万',''))*10000\n",
    "        elif 'm' in art['views']:\n",
    "            art['views'] = float(art['views'].replace('m',''))*1000000\n",
    "            \n",
    "        result = art_coll.update_one({'_id':_id},\n",
    "                                     {'$set':{'stars':int(art['stars']),\n",
    "                                              'likes':int(art['likes']),\n",
    "                                              'views':int(art['views']),\n",
    "                                              'publish_date':parse_ymd(art['publish_date'])}})\n",
    "        return result.modified_count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_field_type(3624725)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 24_MongoDB.ipynb.\r\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib --fname 24_MongoDB.ipynb\n",
    "!mv crawler_from_scratch/RRPM.py RRPM.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress:20.00%\n",
      "time cost: 0 s 5 tasks\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "if __name__ == '__main__': \n",
    "    ids = [i['_id'] for i in art_coll.find()]\n",
    "    IpPool.parallel_task(correct_field_type,ids,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分析数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.cursor.Cursor at 0x10e1a0690>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art_coll.find().limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(art_coll.find().limit(10000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id                      int64\n",
       "html                    object\n",
       "category                object\n",
       "url                     object\n",
       "likes                    int64\n",
       "author_link             object\n",
       "author_name             object\n",
       "publish_date    datetime64[ns]\n",
       "stars                    int64\n",
       "title                   object\n",
       "views                    int64\n",
       "tags                    object\n",
       "dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_df = df.groupby('author_name').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_df['count'] = df.groupby('author_name').count()._id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_df['views_per_artical'] = author_df['views']/author_df['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_df = author_df.sort_values(by='views_per_artical',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id                  2661\n",
       "likes                2661\n",
       "stars                2661\n",
       "views                2661\n",
       "count                2661\n",
       "views_per_artical    2661\n",
       "dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据库导出备份\n",
    "https://cloud.tencent.com/document/product/240/5321"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_coll = db.test\n",
    "test_coll.insert_many(art_coll.find().limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-17T09:17:11.211+0800\tconnected to: mongodb://127.0.0.1:27017/\r\n",
      "2020-04-17T09:17:11.227+0800\texported 10 records\r\n"
     ]
    }
   ],
   "source": [
    "# mongoexport --host 10.66.187.127:27017 -u mongouser -p thepasswordA1 --authenticationDatabase=admin --db=testdb --collection=testcollection -o /data/export_testdb_testcollection.json\n",
    "!mongoexport --host 127.0.0.1:27017 --db=crawler --collection=test -o ./data/export_test_coll.json\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入\n",
    "可以识别date格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-17T09:19:12.501+0800\tconnected to: mongodb://127.0.0.1:27017/\n",
      "2020-04-17T09:19:12.573+0800\t10 document(s) imported successfully. 0 document(s) failed to import.\n"
     ]
    }
   ],
   "source": [
    "# mongoimport --host 10.66.187.127:27017 -u mongouser -p thepasswordA1 --authenticationDatabase=admin --db=testdb --collection=testcollection2 --file=/data/export_testdb_testcollection.json\n",
    "!mongoimport --host 127.0.0.1:27017 --db=crawler --collection=test2 --file=./data/export_test_coll.json\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rrpm文章数据备份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有文章的html源文件\n",
    "rrpm_raw_coll = db.rrpm_raw\n",
    "for i in art_coll.find():\n",
    "# for i in art_coll.find().limit(5):\n",
    "    rrpm_raw_coll.insert_one({'html':i['html'],'url':i['url']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mongoexport --host 127.0.0.1:27017 --db=crawler --collection=rrpm_raw -o ./data/export_rrpm_raw.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重新建立字段数据库\n",
    "把有用的都保存下来，删除原始数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parse_ymd(s):\n",
    "    year_s, mon_s, day_s = s.split('-')\n",
    "    return datetime(int(year_s), int(mon_s), int(day_s))\n",
    "\n",
    "def parse_num(string):\n",
    "    if '万' in string:\n",
    "        return int(float(string.replace('万',''))*10000)\n",
    "    elif 'm' in string:\n",
    "        return int(float(string.replace('m',''))*1000000)\n",
    "    else:\n",
    "        try:\n",
    "            return int(string)\n",
    "        except:\n",
    "            print('error:',string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_comment(soup) -> object:\n",
    "    cmt = {}\n",
    "    comment = soup\n",
    "    comment_author = comment.find('div','comment-author')\n",
    "    if comment_author.a:\n",
    "        cmt['author_name'] = comment_author.a.text.strip()\n",
    "        cmt['author_link'] = comment_author.a['href']\n",
    "    cmt['content'] = comment.find('div','comment-content').text.strip()\n",
    "    cmt['comment_time'] = datetime.strptime(comment.find('span','comment-time')['datetime'],\"%Y-%m-%dT%H:%M:%S+08:00\")\n",
    "    return cmt\n",
    "\n",
    "def parse_comments(soup) -> list:\n",
    "    cmt_list = []\n",
    "    for item in soup.find_all('li','comment'): \n",
    "        cmt_list.append(parse_comment(item))\n",
    "    return cmt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_artical(soup) -> object:\n",
    "    artical = {}\n",
    "    \n",
    "    artical['title'] = soup.h2.text\n",
    "    artical['publish_date'],artical['views'],artical['stars'],artical['likes'] = [item.text.strip() for item in soup.find_all('span','post-meta-item')]\n",
    "    \n",
    "    author_info = soup.find('div','postMetaLockup--authorWithBio')    \n",
    "    artical['author_name'] = author_info.find_all('a')[1].text.strip()    \n",
    "    artical['author_link'] = author_info.find_all('a')[1]['href']    \n",
    "    artical['author_desc'] = author_info.find('div','des').text.strip()  \n",
    "    \n",
    "    main = soup.find('div','grap')\n",
    "    artical['contents'] = list(main.stripped_strings)\n",
    "    artical['imgs'] = [item['src'] for item in main.find_all('img') if 'src' in item.attrs]\n",
    "    \n",
    "    artical['tags'] = [item.text for item in soup.find('div','taglist')] if soup.find('div','taglist') else []\n",
    "    \n",
    "    artical['publish_date'] = parse_ymd(artical['publish_date'])\n",
    "    artical['views'] = parse_num(artical['views'])\n",
    "    artical['stars'] = parse_num(artical['stars'])\n",
    "    artical['likes'] = parse_num(artical['likes'])\n",
    "    \n",
    "    \n",
    "    artical['comments'] = parse_comments(soup)\n",
    "    return artical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_artical_to_mongodb(raw_item):\n",
    "    try:\n",
    "        soup = BeautifulSoup(raw_item['html'],features='lxml')\n",
    "        _id = int(re.search(r'\\d+',raw_item['url']).group())\n",
    "        artical = parse_artical(soup)\n",
    "        artical['_id'] = _id\n",
    "        artical['url'] = raw_item['url']\n",
    "        if not rrpm_articals_coll.insert_one(artical):\n",
    "            print('save failed:',raw_item['url'])\n",
    "            with open('failed_urls.text','a') as f:\n",
    "                f.write(raw_item['url']+'\\n')\n",
    "\n",
    "    except:\n",
    "        print('parse error:',raw_item['url'])\n",
    "        with open('failed_urls.text','a') as f:\n",
    "            f.write(raw_item['url']+'\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrpm_articals_coll = db.rrpm_articals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = rrpm_raw_coll.find()\n",
    "IpPool.parallel_task(save_artical_to_mongodb,items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'APP九宫格如何用Axure画出来？',\n",
       " 'publish_date': datetime.datetime(2018, 7, 30, 0, 0),\n",
       " 'views': 12000,\n",
       " 'stars': 38,\n",
       " 'likes': 9,\n",
       " 'author_name': '浪子',\n",
       " 'author_link': 'http://www.woshipm.com/u/91183',\n",
       " 'author_desc': '微信nuanai88，官网51prd.com下载APP原型。',\n",
       " 'contents': ['九宫格用来平铺展示很多频道或者栏目。那么如何用Axure画出该功能呢?',\n",
       "  '常用场景有“微信APP-我-钱包”、“淘宝APP-首页-频道”、“支付宝APP-首页”。',\n",
       "  '一、原型画法(无交互)',\n",
       "  '九宫格通常包含N个格子，每行3个，每个格子由按钮和图标组成。',\n",
       "  '1. 从默认元件库拖动“中继器”到工作区合适位置。',\n",
       "  '2. 双击该中继器进入内部，即可编辑每一个格子。',\n",
       "  '3. 先画按钮。选择矩形并修改尺寸为125*125px（每行3个，则单个宽度=375/3）。双击输入文字“标题”，然后对齐方式为底部对齐。',\n",
       "  '4. 再画图标。从默认元件库拖动“图片”到合适位置，修改尺寸为75*75px。',\n",
       "  '5. 点击空白区域即可设置中继器属性，添加更多的行，直到9个。这里输入的内容直接代表原型中的每个格子名称。',\n",
       "  '6. 设置中继器的样式，布局改成水平，勾选网格分布，每行项目数为3。',\n",
       "  '7. 回到工作区，就可以看到九宫格效果。',\n",
       "  '8. 生成原型HTML并在浏览器中查看效果。',\n",
       "  '二、原型画法(有交互)',\n",
       "  '九宫格的常见交互效果：点击每个格子，跳转到新页面。',\n",
       "  '接下来以“微信APP-我-钱包”来作为案例详细讲解。',\n",
       "  '9. 修改每个格子的标题，双击Column0的每一行，依次输入对应的标题。',\n",
       "  '10. 然后画出每个宫格对应的页面，总共9个，依次创建。',\n",
       "  '11. 双击该中继器进入内部，选中按钮和图标，进行组合。',\n",
       "  '12. 选择该组合，设置它的交互事件“鼠标单击时”，但是很容易发现无法设置它跳转到哪个页面。因为这个组合代表九个格子，所以理论上应该设置跳转到9个子页面。然后需要利用中继器的属性进行设置。点击column0，然后点击“左侧添加列”，生成Column1这一列。',\n",
       "  '13. 选中Column1的第一行，然后右键点击“引用页面”，然后选择第一个格子对应的子页面。同理设置下面8个行。',\n",
       "  '14. 设置该组合的交互事件“鼠标单击时”，添加动作“链接-打开链接-当前窗口”，组织动作“选中链接到url或文件”，点击“fx”打开“编辑值”弹窗，然后点击“插入变量或函数”，然后选中“中继器/数据集-Column1”，最后确定。',\n",
       "  '15. 生成原型HTML并在浏览器中查看效果。',\n",
       "  '三、添加到APP功能库',\n",
       "  '不同场景下的九宫格功能，标题不一样，样式相对固定。',\n",
       "  '根据多年PM经验，总结出2种常用的“九宫格”，添加到APP元件库，供后续调用。',\n",
       "  '九宫格',\n",
       "  '十六宫格',\n",
       "  '提供源文件下载学习',\n",
       "  'https://pan.baidu.com/s/1lOysRY59IOQN7Hhl7jrI3g',\n",
       "  '相关阅读',\n",
       "  'APP开关功能怎么用Axure画出来',\n",
       "  'APP上导航如何用Axure画出来',\n",
       "  'APP下导航如何通过Axure画出来',\n",
       "  '常见的列表页如何用Axure画出来',\n",
       "  '#专栏作家#',\n",
       "  '浪子，公众号：langzisay，人人都是产品经理专栏作家。业务型PM。',\n",
       "  '本文由 @浪子 原创发布于人人都是产品经理。未经许可，禁止转载。',\n",
       "  '题图来自 Pexels ，基于 CC0 协议'],\n",
       " 'imgs': ['//image.woshipm.com/wp-files/img/46.jpg',\n",
       "  'http://image.woshipm.com/wp-files/2018/07/Lrrj57PX9VgOBPynbjLn.png',\n",
       "  'http://image.woshipm.com/wp-files/2018/07/L0oHDKfSeeswkCqpbSjz.png',\n",
       "  'http://image.woshipm.com/wp-files/2018/07/a2f42tgyKXguxKWMyESO.png',\n",
       "  'http://image.woshipm.com/wp-files/2018/07/FFcgw5Y2rAX1WT8dolAH.png',\n",
       "  'http://image.woshipm.com/wp-files/2018/07/SQuW20ckRspTwCcgfw41.png',\n",
       "  'http://image.woshipm.com/wp-files/2018/07/LRbDowVUUPkNNfNbhRyA.png',\n",
       "  'http://image.woshipm.com/wp-files/2018/07/4vHZjRfIWYshUI86OGiI.png',\n",
       "  'http://image.woshipm.com/wp-files/2018/07/CLapeVxNDuxf4l61aED0.png',\n",
       "  'http://image.woshipm.com/wp-files/2018/07/gFSHp5aank0nFwcC4io7.png',\n",
       "  'http://image.woshipm.com/wp-files/2018/07/Zjh4Jwtl7L0iVvChubwt.png',\n",
       "  'http://image.woshipm.com/wp-files/2018/07/Ukp5bvwdBNfFMYezIQgw.png',\n",
       "  'http://image.woshipm.com/wp-files/2018/07/bXSZmD0oZeYzQb8Fd31L.png',\n",
       "  'http://image.woshipm.com/wp-files/2018/07/SaTOZus731Qs1lfGByab.png',\n",
       "  'http://image.woshipm.com/wp-files/2018/07/mjVKEDS8xzQerxUjCfjg.png',\n",
       "  'http://image.woshipm.com/wp-files/2018/07/HMDRbuDsmHkeUSmT2feH.png',\n",
       "  'http://image.woshipm.com/wp-files/2018/07/IjhgXW4pdNemnJH8xm8L.gif',\n",
       "  'http://image.woshipm.com/wp-files/2018/07/ezMYbQ4gOD4RIkiaj9ZW.png',\n",
       "  'http://image.woshipm.com/wp-files/2018/07/vSGF4shhIf4Pb2fmcKHZ.png'],\n",
       " 'tags': ['2年', 'APP九宫格', '初级'],\n",
       " 'comments': [{'author_name': '.',\n",
       "   'author_link': 'http://www.woshipm.com/u/912571',\n",
       "   'content': '请教一下老师',\n",
       "   'comment_time': datetime.datetime(2019, 7, 11, 23, 55, 38)},\n",
       "  {'author_name': '.',\n",
       "   'author_link': 'http://www.woshipm.com/u/912571',\n",
       "   'content': '怎么加给每一项单独加图片呢',\n",
       "   'comment_time': datetime.datetime(2019, 7, 11, 23, 55, 27)},\n",
       "  {'author_name': '浪子',\n",
       "   'author_link': 'http://www.woshipm.com/u/91183',\n",
       "   'content': '不需要给每一项都添加图片，只需要添加一次。\\n中继器的特性就是可复用。你拖一个中继器去工作区，双击之后添加任何内容都会自动变成多份的。',\n",
       "   'comment_time': datetime.datetime(2019, 7, 16, 22, 18, 8)},\n",
       "  {'author_name': '小机灵鬼',\n",
       "   'author_link': 'http://www.woshipm.com/u/699311',\n",
       "   'content': '好厉害',\n",
       "   'comment_time': datetime.datetime(2018, 7, 30, 17, 6, 32)}]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = rrpm_raw_coll.find_one({'url':'http://www.woshipm.com/rp/1173879.html'})\n",
    "soup = BeautifulSoup(item['html'],features='lxml')\n",
    "parse_artical(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<img alt=\"\" class=\"size-full wp-image-1906244 aligncenter\" data-action=\"zoom\" height=\"450\" src=\"http://image.woshipm.com/wp-files/2019/02/kql0MPNs9GaZbm7vNMH2.jpg\" width=\"800\"/>\n",
      "<img alt=\"\" class=\"aligncenter\" data-action=\"zoom\" height=\"440\" src=\"http://image.woshipm.com/wp-files/2019/03/N6I9MoJGzxRIbtOt4DWG.png\" width=\"1105\"/>\n",
      "<img alt=\"\" class=\"aligncenter\" data-action=\"zoom\" height=\"325\" src=\"http://image.woshipm.com/wp-files/2019/03/9VeTexI9KkNgI7VtugUm.png\" width=\"1096\"/>\n",
      "<img alt=\"\" class=\"aligncenter\" data-action=\"zoom\" height=\"396\" src=\"http://image.woshipm.com/wp-files/2019/03/AwQLH4zj6cWl0sCifFhk.png\" width=\"1096\"/>\n",
      "<img class=\"aligncenter\" data-action=\"zoom\" src=\"http://image.woshipm.com/wp-files/2019/02/0L0CQnnyF8KjptbbxYJJ.png\"/>\n",
      "<img alt=\"\" class=\"aligncenter\" data-action=\"zoom\" height=\"498\" src=\"http://image.woshipm.com/wp-files/2019/03/EGrtPxX72DvKz3abyxc0.png\" width=\"1106\"/>\n",
      "<img class=\"aligncenter\" data-action=\"zoom\" src=\"http://image.woshipm.com/wp-files/2019/02/oKikZvuRO8ACeFnMKm7Z.png\"/>\n",
      "<img alt=\"硬件产品经理进阶指南\" class=\"aligncenter\" data-action=\"zoom\" src=\"http://image.woshipm.com/wp-files/2019/02/Grci5YQoEXCQpaGy9jqy.png\" title=\"硬件产品经理进阶指南\"/>\n",
      "<img class=\"aligncenter\" data-action=\"zoom\"/>\n",
      "<img class=\"aligncenter\" data-action=\"zoom\" src=\"http://image.woshipm.com/wp-files/2019/02/YqfiOCP2kQNhgaJGuaec.png\"/>\n"
     ]
    }
   ],
   "source": [
    "for item in soup.find('div','grap').find_all('img'):\n",
    "    print(item)\n",
    "#     if 'src' in item.attrs:\n",
    "#         print(item)\n",
    "#     print(item['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "with open('failed_urls.text','r') as f:\n",
    "    for item in f.readlines():\n",
    "        urls.append(item.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task(url):\n",
    "    item = rrpm_raw_coll.find_one({'url':url})\n",
    "    save_artical_to_mongodb(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse error: http://www.woshipm.com/pmd/1901056.html\n"
     ]
    }
   ],
   "source": [
    "task(urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IpPool.parallel_task(task,urls[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 发布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 5f047ef] clean data\r\n",
      " 1 file changed, 98 insertions(+), 39 deletions(-)\r\n"
     ]
    }
   ],
   "source": [
    "!git add 24_MongoDB.ipynb\n",
    "!git commit -m \"clean data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbdev_build_lib --fname 24_MongoDB.ipynb\n",
    "!mv crawler_from_scratch/RRPM.py RRPM.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

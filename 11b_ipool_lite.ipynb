{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp IPool_lite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "核心就是去掉数据库，把这几百条数据放内存里查询&修改，定期备份成txt\n",
    "\n",
    "核心路径是get_ip，所以初始化操作也在这里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import json,random,requests,re,time\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 核心"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取一个ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "db = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_ip() -> str:\n",
    "    '健康值作为权重，随机抽取一个ip'\n",
    "    global db\n",
    "    ips = random.choices(list(db.keys()),weights=db.values(),k=1)\n",
    "    return ips[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'100,9.37.17.19:88'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = {'39.137.107.9:8080':100,'100,9.37.17.19:88':52}\n",
    "_get_ip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 更新健康值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def update_health(ip,is_good=False) -> int:\n",
    "    '更新ip的health值，好用+1，无效/2'\n",
    "    db[ip] = db[ip]+1 if is_good else db[ip]/2\n",
    "    return db[ip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip = '100,9.37.17.19:88'\n",
    "update_health(ip,is_good=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 进阶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 爬取ip网站\n",
    "> 搜索全部tr，然后解析符合的ip，不符合的就不管"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "sites = '''\n",
    "https://www.kuaidaili.com/free/inha/\n",
    "http://www.nimadaili.com/gaoni/\n",
    "http://www.xiladaili.com/gaoni/\n",
    "https://ip.jiangxianli.com/?anonymity=2\n",
    "https://www.7yip.cn/free/\n",
    "http://www.ip3366.net/free/\n",
    "https://list.proxylistplus.com/Fresh-HTTP-Proxy-List-1\n",
    "http://proxyslist.com/\n",
    "'''.strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def match_ip(tag): return re.match(r'^(\\d{1,3}\\.){3}\\d{1,3}$',tag.text.strip())\n",
    "def match_port(tag): return re.match(r'^\\d{2,5}$',tag.text.strip())\n",
    "def match_ip_with_port(tag): return re.match(r'^(\\d{1,3}\\.){3}\\d{1,3}:\\d{2,5}$',tag.text.strip())\n",
    "\n",
    "def _parse_ip(soup) -> str:\n",
    "    ip_with_port = soup.find(match_ip_with_port)\n",
    "    ip = soup.find(match_ip)\n",
    "    port = soup.find(match_port)\n",
    "    if ip_with_port: return ip_with_port.text\n",
    "    elif ip and port: return ip.text+':'+port.text\n",
    "#     else: print('parse ip error:',soup)\n",
    "\n",
    "def parse_ips(url) -> iter:\n",
    "    res = requests.get(url,headers={'user-agent':'Mozilla/5.0'})\n",
    "    soup = BeautifulSoup(res.text,features='lxml')\n",
    "    tr_items = soup.body.find_all('tr')\n",
    "    for tr in tr_items:\n",
    "        ip = _parse_ip(tr) \n",
    "        if ip: yield ip\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def save_ips(ips) -> int:\n",
    "    'ips保存到db和txt中，并且返回新增ip个数'\n",
    "    global db\n",
    "    keys = db.keys()\n",
    "    count_new = 0\n",
    "    for ip in ips:\n",
    "        if ip not in keys:\n",
    "            db[ip] = 100\n",
    "            count_new += 1\n",
    "    with open('ipool.txt','w') as f:\n",
    "        json.dump(db,f)\n",
    "    return count_new\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def crawl_ips():\n",
    "    '爬取并保存ip'\n",
    "    global sites,db\n",
    "    for url in sites:\n",
    "        try:\n",
    "            ips = list(parse_ips(url))  \n",
    "            count_new = save_ips(ips)\n",
    "            print(url,' 新增：',count_new)\n",
    "        except:\n",
    "            print('error',url)\n",
    "    print('总库存：',len(db.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.kuaidaili.com/free/inha/  新增： 0\n",
      "http://www.nimadaili.com/gaoni/  新增： 0\n",
      "http://www.xiladaili.com/gaoni/  新增： 8\n",
      "https://ip.jiangxianli.com/?anonymity=2  新增： 2\n",
      "https://www.7yip.cn/free/  新增： 0\n",
      "http://www.ip3366.net/free/  新增： 0\n",
      "https://list.proxylistplus.com/Fresh-HTTP-Proxy-List-1  新增： 0\n",
      "http://proxyslist.com/  新增： 0\n",
      "总库存： 203\n"
     ]
    }
   ],
   "source": [
    "crawl_ips()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代理请求\n",
    "分支可用于验证ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parse_protocal(url): return 'https' if 'https' in url else 'http'\n",
    "\n",
    "def _proxy_request(url,ip,method='get') -> object:\n",
    "    '代理请求，并更新ip的health'\n",
    "    protocal = parse_protocal(url)\n",
    "    proxies = {protocal: protocal+'://'+ip}\n",
    "    \n",
    "    try:\n",
    "        res = requests.request(method,url,\n",
    "                               headers={'user-agent':'Mozilla/5.0'},\n",
    "                               proxies=proxies,\n",
    "                               allow_redirects=False,\n",
    "                               timeout=5)\n",
    "    except:\n",
    "        update_health(ip)\n",
    "        print('except error:',ip,db[ip])\n",
    "        return\n",
    "    else:\n",
    "        if res and res.status_code == 200: update_health(ip,is_good=True)\n",
    "        else: update_health(ip)\n",
    "        print(res,ip,db[ip])\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def proxy_request(url,method='get',repeat_times=10) -> object:\n",
    "    '自动获取一个随机ip，不断重复请求，直到200'\n",
    "    current_times = 1\n",
    "    while current_times <= repeat_times:\n",
    "        ip = get_ip()\n",
    "        res = _proxy_request(url,ip,method)\n",
    "        if res and res.status_code == 200: \n",
    "            return res\n",
    "        else: \n",
    "            print(url,'times:',current_times,res)\n",
    "            current_times += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "删除： 0 剩余： 203\n",
      "https://www.kuaidaili.com/free/inha/  新增： 0\n",
      "http://www.nimadaili.com/gaoni/  新增： 29\n",
      "http://www.xiladaili.com/gaoni/  新增： 46\n",
      "https://ip.jiangxianli.com/?anonymity=2  新增： 2\n",
      "https://www.7yip.cn/free/  新增： 0\n",
      "http://www.ip3366.net/free/  新增： 0\n",
      "https://list.proxylistplus.com/Fresh-HTTP-Proxy-List-1  新增： 0\n",
      "http://proxyslist.com/  新增： 25\n",
      "总库存： 305\n",
      "except error: 163.204.247.147:9999 50.0\n",
      "https://www.baidu.com/ times: 1 None\n",
      "删除： 0 剩余： 305\n",
      "https://www.kuaidaili.com/free/inha/  新增： 0\n",
      "http://www.nimadaili.com/gaoni/  新增： 0\n",
      "http://www.xiladaili.com/gaoni/  新增： 0\n",
      "https://ip.jiangxianli.com/?anonymity=2  新增： 0\n",
      "https://www.7yip.cn/free/  新增： 0\n",
      "http://www.ip3366.net/free/  新增： 0\n",
      "https://list.proxylistplus.com/Fresh-HTTP-Proxy-List-1  新增： 0\n",
      "http://proxyslist.com/  新增： 0\n",
      "总库存： 305\n",
      "except error: 59.62.25.62:9000 50.0\n",
      "https://www.baidu.com/ times: 2 None\n",
      "except error: 68.183.188.100:3128 50.0\n",
      "https://www.baidu.com/ times: 3 None\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.baidu.com/'\n",
    "proxy_request(url,repeat_times=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def validate_ips(url='http://www.baidu.com/',max_workers=100):\n",
    "    global db\n",
    "    ips = list(db.keys())\n",
    "    parallel_task(lambda ip:_proxy_request(url, ip),ips,max_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_ips()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取&自动更新ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "last_modify = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def delete_ips():\n",
    "    '删除不健康的ip，节省内存，提高抽取效率'\n",
    "    global db\n",
    "    keys = list(db.keys())\n",
    "    count_before = len(keys)\n",
    "    for k in keys:\n",
    "        if db[k] < 50: del db[k]\n",
    "    count_current = len(db.keys())\n",
    "    print('删除：',count_before-count_current,'剩余：',count_current)\n",
    "\n",
    "def get_ip():\n",
    "    '5min爬一次ip网站，1h删一次劣质ip'\n",
    "    global db\n",
    "    # 如果db为空，则尝试从txt文件读取\n",
    "    if not db: \n",
    "        if Path('ipool.txt').exists():\n",
    "            with open('ipool.txt','r') as f:\n",
    "                db = json.load(f)\n",
    "    \n",
    "    interval_task(delete_ips,'delete',interval=3600)\n",
    "    interval_task(crawl_ips,'crawl')\n",
    "    \n",
    "    return _get_ip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'118.69.50.154:80'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 工具\n",
    "## 周期任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def interval_task(fn,name,interval=300):\n",
    "    '每5min自动执行fn'\n",
    "    global last_modify\n",
    "    if name not in last_modify or (time.time()-last_modify[name]) > interval:\n",
    "        last_modify[name] = time.time()\n",
    "        fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 并行任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_progress_bar(r,length=30) -> str:\n",
    "    # 类似于这样的进度条'[#######                                          ]14.87%'\n",
    "    current = int(length*r)\n",
    "    rest = int(length*(1-r))\n",
    "    return '['+'#'*current+' '*rest+'] '+str(r*100)[:5]+'%'\n",
    "\n",
    "def show_current_progress(done_num,total_num,start_time):\n",
    "    pct = done_num/total_num\n",
    "    now = time.time()\n",
    "    cost_time = int(now-start_time)\n",
    "    left_time = int(cost_time/done_num*(total_num-done_num))\n",
    "    print(f'progress:{get_progress_bar(pct)} | cost:{cost_time}s | left:{left_time}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _parallel_task(fn,loop_args,max_workers=3):\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        for data in executor.map(fn,loop_args):\n",
    "            yield data\n",
    "\n",
    "def parallel_task(fn,loop_args,max_workers=3):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    done_num = 0\n",
    "    total_num = len(loop_args)\n",
    "    \n",
    "    results = _parallel_task(fn,loop_args,max_workers)\n",
    "    for data in results:\n",
    "        done_num += 1\n",
    "        interval_task(lambda:show_current_progress(done_num,total_num,start_time),'progress',1)\n",
    "#         print('output data:',data)\n",
    "    \n",
    "    cost_time = int(time.time()-start_time)\n",
    "    print(f'{total_num} tasks, {cost_time}s')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress:[########                     ] 27.27% | cost:10s | left:26s\n"
     ]
    }
   ],
   "source": [
    "show_current_progress(3,11,time.time()-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def say_hi(i): \n",
    "    t = random.randint(1,10)\n",
    "    time.sleep(t)\n",
    "    return f'hi end {i} {t}'\n",
    "\n",
    "parallel_task(say_hi,range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 发布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 11b_ipool_lite.ipynb.\r\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "!nbdev_build_lib --fname 11b_ipool_lite.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp crawler_from_scratch/IPool_lite.py /Users/Neo/learn_fastai_from_scratch/IPool_lite.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 90c4104] fix init issue\r\n",
      " 2 files changed, 65 insertions(+), 131 deletions(-)\r\n"
     ]
    }
   ],
   "source": [
    "!git add 11b_ipool_lite.ipynb\n",
    "!git add crawler_from_scratch/IPool_lite.py\n",
    "\n",
    "!git commit -m \"fix init issue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 优化\n",
    "\n",
    "爬取ip，出问题时try except，保证程序正常运作\n",
    "\n",
    "如果线上跑的时候，把各种错误写到log文件中，或者用一个比较明显的方式显示进度，但其他的log会一直存在"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

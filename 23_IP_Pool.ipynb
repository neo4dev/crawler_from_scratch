{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp IpPool\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代理池\n",
    "实现效果\n",
    "1. 自动抓取新ip\n",
    "* 自动删除无效ip（根据健康度）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import re,random,time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import requests,redis \n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取一个可用ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def connect_db() -> object:\n",
    "    connection_pool = redis.ConnectionPool(host='localhost', port=6379, decode_responses=True)\n",
    "    rdb = redis.Redis(connection_pool=connection_pool)\n",
    "    return rdb\n",
    "\n",
    "def _get_ip(protocal='http') -> str:\n",
    "    '把health作为权重，随机抽取ip'\n",
    "    rdb = connect_db()\n",
    "    prim_ips = rdb.zrange(protocal,-20,-1)    \n",
    "    return random.choice(prim_ips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_data():\n",
    "    rdb = connect_db()\n",
    "    rdb.zadd('http',{'39.137.107.9:8080':10}) \n",
    "    rdb.zadd('https',{'39.137.107.9:8080':10})        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'117.88.177.109:3000'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make_test_data()\n",
    "_get_ip()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 更新健康值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def update_health(ip,is_health=False,protocal='http') -> float:\n",
    "    rdb = connect_db()\n",
    "    increase = 1 if is_health else -10\n",
    "    result = rdb.zincrby(protocal,increase,ip)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_health('128.199.246.10:44344',is_health=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 爬取ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "proxy_website_urls = '''\n",
    "https://www.kuaidaili.com/free/inha/\n",
    "http://www.nimadaili.com/gaoni/\n",
    "http://www.xiladaili.com/gaoni/\n",
    "https://ip.jiangxianli.com/?anonymity=2\n",
    "https://www.7yip.cn/free/\n",
    "http://www.ip3366.net/free/\n",
    "https://list.proxylistplus.com/Fresh-HTTP-Proxy-List-1\n",
    "http://proxyslist.com/\n",
    "'''.strip().split('\\n')\n",
    "\n",
    "def match_ip(tag): return re.match(r'^(\\d{1,3}\\.){3}\\d{1,3}$',tag.text.strip())\n",
    "def match_port(tag): return re.match(r'^\\d{2,5}$',tag.text.strip())\n",
    "def match_ip_with_port(tag): return re.match(r'^(\\d{1,3}\\.){3}\\d{1,3}:\\d{2,5}$',tag.text.strip())\n",
    "\n",
    "def find_port(ip_item_soup) -> str:\n",
    "    soup = ip_item_soup\n",
    "    while True:\n",
    "        # 不停的查找包含port的父级\n",
    "        soup = soup.parent\n",
    "        if len(soup.find_all(match_ip)) > 1:\n",
    "#             print('解析port失败',soup)\n",
    "            return \n",
    "        if soup.find(match_port): \n",
    "            return soup.find(match_port).text.strip()\n",
    "\n",
    "def find_ips(soup) -> iter:\n",
    "    '从soup中解析出ip和port'\n",
    "    # 39.137.107.98:80这种情况\n",
    "    if soup.find_all(match_ip_with_port):\n",
    "        for item in soup.find_all(match_ip_with_port):\n",
    "            yield item.text.strip()\n",
    "    # 39.137.107.98 | 80这种情况\n",
    "    elif soup.find_all(match_ip):\n",
    "        for item in soup.find_all(match_ip):\n",
    "            ip = item.text.strip()\n",
    "            port = find_port(item)\n",
    "            if port: yield ip+':'+port\n",
    "    else:\n",
    "        print('解析失败：',soup)\n",
    "        \n",
    "        \n",
    "# 这里没想好，到底http和https都爬，然后自动切换还是手动\n",
    "def crawl_ip(url,protocal='http'):\n",
    "    '爬取1个页面的ip'\n",
    "    rdb = connect_db()\n",
    "    increase = 0\n",
    "    \n",
    "    res = requests.get(url,headers={'user-agent':'Mozilla/5.0'})\n",
    "    if res.status_code == 200:\n",
    "        soup = BeautifulSoup(res.text,features='lxml')\n",
    "        for ip in find_ips(soup):\n",
    "            \n",
    "            if rdb.zadd('http',{ip:100},nx=True):\n",
    "                increase += 1\n",
    "        stock = rdb.zcount(protocal,0,100000)\n",
    "        print(f'{url} 新增：{increase}，库存更新为：{stock}个')\n",
    "    else:\n",
    "        print(url,res,'requests请求失败')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.nimadaili.com/gaoni/ 新增：47，库存更新为：303个\n"
     ]
    }
   ],
   "source": [
    "crawl_ip(proxy_website_urls[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 校验IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def validate(ip,url='http://m.sm.cn/',timeout=5) -> float:\n",
    "    protocal = url.split(':')[0]\n",
    "    proxies={protocal: protocal+'://'+ip}\n",
    "    try:\n",
    "        res = requests.get(url,\n",
    "                           headers={'user-agent':'Mozilla/5.0'},\n",
    "                           proxies=proxies,\n",
    "                           timeout=timeout)\n",
    "    except:\n",
    "        return update_health(ip,is_health=False,protocal=protocal)\n",
    "    else:\n",
    "        if res and res.status_code == 200:\n",
    "            return update_health(ip,is_health=True,protocal=protocal)\n",
    "        else:\n",
    "            return update_health(ip,is_health=False,protocal=protocal)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate('128.199.246.10:44344')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定期更新IP\n",
    ">5min更新一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "last_crawl = 0\n",
    "def parallel_crawl_ips():\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        executor.map(crawl_ip, proxy_website_urls) \n",
    "def repeat_crawl_ips(frequency=300):\n",
    "    global last_crawl\n",
    "    now = time.time()\n",
    "    if last_crawl//frequency != now//frequency:\n",
    "        last_crawl = now\n",
    "        parallel_crawl_ips()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.nimadaili.com/gaoni/ 新增：43，库存更新为：346个\n",
      "http://www.xiladaili.com/gaoni/ 新增：0，库存更新为：346个\n",
      "http://www.ip3366.net/free/ 新增：3，库存更新为：349个\n",
      "https://www.kuaidaili.com/free/inha/ 新增：1，库存更新为：350个\n",
      "https://www.7yip.cn/free/ 新增：2，库存更新为：352个\n",
      "https://ip.jiangxianli.com/?anonymity=2 新增：6，库存更新为：358个\n",
      "http://proxyslist.com/ 新增：22，库存更新为：380个\n",
      "https://list.proxylistplus.com/Fresh-HTTP-Proxy-List-1 新增：0，库存更新为：380个\n"
     ]
    }
   ],
   "source": [
    "repeat_crawl_ips()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定期删除IP\n",
    "> 每日删除health为0的IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = connect_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.zrem('http','128.199.246.10:44344')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.zscan('http',match='128.199.246.10:44344')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.zrange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r.zcount('http',0,20)\n",
    "r.zremrangebyscore('http',0,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# 这里也是，没想好，怎么维护http和https两个库\n",
    "\n",
    "last_delete = 0\n",
    "def delete_ips(protocal='http'):\n",
    "    rdb = connect_db()\n",
    "    result = rdb.zremrangebyscore(protocal,0,20) \n",
    "    return result\n",
    "    \n",
    "def repeat_delete_ips(frequency=24*3600):\n",
    "    global last_delete\n",
    "    now = time.time()\n",
    "    \n",
    "    if last_delete//frequency != now//frequency:\n",
    "        last_delete = now\n",
    "        result = delete_ips()\n",
    "        print('移除：',result,'个IP')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "移除： 0 个IP\n"
     ]
    }
   ],
   "source": [
    "repeat_delete_ips()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自动维护IP池"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_ip(protocal='http') -> str:\n",
    "    repeat_crawl_ips()\n",
    "    repeat_delete_ips()\n",
    "    return _get_ip(protocal)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'39.137.69.8:80'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 发布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "!nbdev_build_lib --fname 23_IP_Pool.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add 23_IP_Pool.ipynb\n",
    "!git commit -m \"fix ip increase num\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

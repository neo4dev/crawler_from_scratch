{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp IpPool\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代理池\n",
    "实现效果\n",
    "1. 自动抓取新ip\n",
    "* 自动删除无效ip（根据健康度）\n",
    "\n",
    "任务：\n",
    "* 显示优质ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import re,random,time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import requests,redis \n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取一个可用ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def connect_db() -> object:\n",
    "    connection_pool = redis.ConnectionPool(host='localhost', port=6379, decode_responses=True)\n",
    "    rdb = redis.Redis(connection_pool=connection_pool)\n",
    "    return rdb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "rdb = connect_db()\n",
    "def _get_ip(protocal='http') -> str:\n",
    "    '把health作为权重，随机抽取ip'\n",
    "    prim_ips = rdb.zrange(protocal,-20,-1)    \n",
    "    return random.choice(prim_ips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_data():\n",
    "    rdb = connect_db()\n",
    "    rdb.zadd('http',{'39.137.107.9:8080':10}) \n",
    "    rdb.zadd('https',{'39.137.107.9:8080':10})        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'39.137.69.6:80'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make_test_data()\n",
    "_get_ip()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('94.179.135.230:54393', 100.0),\n",
       " ('94.205.254.82:3128', 100.0),\n",
       " ('95.79.55.196:53281', 100.0),\n",
       " ('35.247.242.31:3128', 205.0),\n",
       " ('34.89.173.90:3128', 213.0),\n",
       " ('52.179.231.206:80', 221.0),\n",
       " ('39.137.69.7:8080', 305.0),\n",
       " ('39.137.69.6:8080', 320.0),\n",
       " ('39.137.69.6:80', 346.0),\n",
       " ('52.80.58.248:3128', 359.0),\n",
       " ('47.112.46.46:80', 450.0),\n",
       " ('58.176.150.177:80', 593.0),\n",
       " ('61.147.210.159:8118', 1436.0),\n",
       " ('39.137.69.10:8080', 1503.0),\n",
       " ('39.137.69.7:80', 1570.0),\n",
       " ('61.147.210.159:8080', 1579.0),\n",
       " ('39.137.69.9:80', 1685.0),\n",
       " ('39.137.69.10:80', 1707.0),\n",
       " ('39.137.69.8:80', 1818.0),\n",
       " ('221.180.170.104:8080', 2188.0)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prim_ips = rdb.zrange('http',-20,-1,withscores=True)\n",
    "prim_ips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 更新健康值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def update_health(ip,is_health=False,protocal='http') -> float:\n",
    "    increase = 1 if is_health else -int(rdb.zscore(protocal,ip)/2)\n",
    "    result = rdb.zincrby(protocal,increase,ip)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_health('39.137.107.9:8080',is_health=False,protocal='https')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 爬取ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "proxy_website_urls = '''\n",
    "https://www.kuaidaili.com/free/inha/\n",
    "http://www.nimadaili.com/gaoni/\n",
    "http://www.xiladaili.com/gaoni/\n",
    "https://ip.jiangxianli.com/?anonymity=2\n",
    "https://www.7yip.cn/free/\n",
    "http://www.ip3366.net/free/\n",
    "https://list.proxylistplus.com/Fresh-HTTP-Proxy-List-1\n",
    "http://proxyslist.com/\n",
    "'''.strip().split('\\n')\n",
    "\n",
    "def match_ip(tag): return re.match(r'^(\\d{1,3}\\.){3}\\d{1,3}$',tag.text.strip())\n",
    "def match_port(tag): return re.match(r'^\\d{2,5}$',tag.text.strip())\n",
    "def match_ip_with_port(tag): return re.match(r'^(\\d{1,3}\\.){3}\\d{1,3}:\\d{2,5}$',tag.text.strip())\n",
    "\n",
    "def find_port(ip_item_soup) -> str:\n",
    "    soup = ip_item_soup\n",
    "    while True:\n",
    "        # 不停的查找包含port的父级\n",
    "        soup = soup.parent\n",
    "        if len(soup.find_all(match_ip)) > 1:\n",
    "#             print('解析port失败',soup)\n",
    "            return \n",
    "        if soup.find(match_port): \n",
    "            return soup.find(match_port).text.strip()\n",
    "\n",
    "def find_ips(soup) -> iter:\n",
    "    '从soup中解析出ip和port'\n",
    "    # 39.137.107.98:80这种情况\n",
    "    if soup.find_all(match_ip_with_port):\n",
    "        for item in soup.find_all(match_ip_with_port):\n",
    "            yield item.text.strip()\n",
    "    # 39.137.107.98 | 80这种情况\n",
    "    elif soup.find_all(match_ip):\n",
    "        for item in soup.find_all(match_ip):\n",
    "            ip = item.text.strip()\n",
    "            port = find_port(item)\n",
    "            if port: yield ip+':'+port\n",
    "    else:\n",
    "        print('解析失败：',soup)\n",
    "        \n",
    "        \n",
    "# 这里没想好，到底http和https都爬，然后自动切换还是手动\n",
    "def crawl_ip(url,protocal='http'):\n",
    "    '爬取1个页面的ip'\n",
    "    increase = 0\n",
    "    \n",
    "    res = requests.get(url,headers={'user-agent':'Mozilla/5.0'})\n",
    "    if res.status_code == 200:\n",
    "        soup = BeautifulSoup(res.text,features='lxml')\n",
    "        for ip in find_ips(soup):\n",
    "            \n",
    "            if rdb.zadd('http',{ip:100},nx=True):\n",
    "                increase += 1\n",
    "        stock = rdb.zcount(protocal,0,100000)\n",
    "        print(f'{url} 新增：{increase}，库存更新为：{stock}个')\n",
    "    else:\n",
    "        print(url,res,'requests请求失败')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawl_ip(proxy_website_urls[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 校验IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def validate(ip,url='http://m.sm.cn/',timeout=5) -> float:\n",
    "    protocal = url.split(':')[0]\n",
    "    proxies={protocal: protocal+'://'+ip}\n",
    "    try:\n",
    "        res = requests.get(url,\n",
    "                           headers={'user-agent':'Mozilla/5.0'},\n",
    "                           proxies=proxies,\n",
    "                           timeout=timeout)\n",
    "    except:\n",
    "        return update_health(ip,is_health=False,protocal=protocal)\n",
    "    else:\n",
    "        if res and res.status_code == 200:\n",
    "            return update_health(ip,is_health=True,protocal=protocal)\n",
    "        else:\n",
    "            return update_health(ip,is_health=False,protocal=protocal)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate('128.199.246.10:44344')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定期更新IP\n",
    ">5min更新一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "last_crawl = 0\n",
    "def parallel_crawl_ips():\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        executor.map(crawl_ip, proxy_website_urls) \n",
    "def repeat_crawl_ips(frequency=300):\n",
    "    global last_crawl\n",
    "    now = time.time()\n",
    "    if last_crawl//frequency != now//frequency:\n",
    "        last_crawl = now\n",
    "        parallel_crawl_ips()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_crawl_ips()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定期删除IP\n",
    "> 每日删除health为0的IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# 这里也是，没想好，怎么维护http和https两个库\n",
    "\n",
    "last_delete = 0\n",
    "def delete_ips(protocal='http'):\n",
    "    result = rdb.zremrangebyscore(protocal,0,20) \n",
    "    return result\n",
    "    \n",
    "def repeat_delete_ips(frequency=24*3600):\n",
    "    global last_delete\n",
    "    now = time.time()\n",
    "    \n",
    "    if last_delete//frequency != now//frequency:\n",
    "        last_delete = now\n",
    "        result = delete_ips()\n",
    "        print('移除：',result,'个IP')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_delete_ips()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自动维护IP池"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_ip(protocal='http') -> str:\n",
    "    repeat_crawl_ips()\n",
    "    repeat_delete_ips()\n",
    "    return _get_ip(protocal)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代理请求\n",
    "1. 失败换ip重新请求\n",
    "* 超过10次log下来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def proxy_get(url) -> object:\n",
    "    repeat_count = 0\n",
    "    while repeat_count<10:\n",
    "        repeat_count += 1\n",
    "\n",
    "        protocal = url.split(':')[0]\n",
    "        ip = get_ip(protocal=protocal)\n",
    "        proxies={protocal: protocal+'://'+ip}\n",
    "        \n",
    "        try:\n",
    "            res = requests.get(url,\n",
    "                               headers={'user-agent':'Mozilla/5.0'},\n",
    "                               proxies=proxies,\n",
    "                               timeout=5)\n",
    "        except:\n",
    "            # 报错 重来 health-\n",
    "            update_health(ip,False,protocal)            \n",
    "        else:\n",
    "            # 有些200的text中确实bad request\n",
    "            if res and res.status_code == 200 and len(res.text)>100:\n",
    "                # 200 & html存在，则保存 break health+\n",
    "                update_health(ip,True,protocal)            \n",
    "                print('success:',url,'try times:',repeat_count)\n",
    "                return res\n",
    "            elif res and res.status_code == 404:\n",
    "                # 404 log break health+\n",
    "                with open('rrpm.log','a') as f:\n",
    "                    f.write(f'{url} 404\\n')\n",
    "                update_health(ip,True,protocal)  \n",
    "                break \n",
    "            else:\n",
    "                # 其他,比如访问过快 重来 health-\n",
    "                update_health(ip,False,protocal)   \n",
    "    print('overtry:',url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = proxy_get('http://www.woshipm.com/category/operate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 并发任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parallel_task(fn,task_arg_list,max_workers=100) -> list:\n",
    "    data_list = []\n",
    "    completed_num = 0\n",
    "    task_num = len(task_arg_list)\n",
    "    start_time = time.time()\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        for data in executor.map(fn,task_arg_list):\n",
    "            data_list.append(data)\n",
    "            completed_num += 1\n",
    "            print('progress:{:.2%}'.format(completed_num/task_num))     \n",
    "    end_time = time.time()\n",
    "    print('time cost:',int(end_time - start_time),'s',len(task_arg_list),'urls')\n",
    "    return data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 发布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 23_IP_Pool.ipynb.\r\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "!nbdev_build_lib --fname 23_IP_Pool.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 9a17c01] use one redis connect\r\n",
      " 1 file changed, 78 insertions(+), 187 deletions(-)\r\n"
     ]
    }
   ],
   "source": [
    "!git add 23_IP_Pool.ipynb\n",
    "!git commit -m \"use one redis connect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redis.exceptions.ConnectionError: Error 8 connecting to localhost:6379. nodename nor servname provided, or not known.\n",
    "# 由于redis给没有用户名的用户，有连接数限制\n",
    "!ulimit -n 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

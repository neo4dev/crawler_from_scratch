# AUTOGENERATED! DO NOT EDIT! File to edit: 01_Advanced_Request.ipynb (unless otherwise specified).

__all__ = ['format_cookie_str', 'get_children', 'get_class', 'get_all_class', 'get_class_count', 'is_content_list',
           'find_main_list', 'is_next_page', 'get_next_page_url', 'get_child_navigablestring', 'get_data_name',
           'get_data']

# Cell
import requests,json,re
from bs4 import BeautifulSoup,Tag,NavigableString
from collections import Counter

# Cell
def format_cookie_str(cookie_str):
    '把chrome拷贝过来的cookie字符转化成dict'
    cookies = {}
    for item in cookie_str.split('; '):
        k,v = item.split('=',1)
        cookies[k] = v
    return cookies

# Cell
def get_children(soup): return [c for c in soup.children if isinstance(c,Tag)]

def get_class(soup):
    '获取单个tag的class，没有则显示no_class'
    if 'class' in soup.attrs and soup.attrs['class']:
        return soup.attrs['class']
    else:
        return ['no_class']

def get_all_class(soup):
    '收集每个tag的class，没有则显示no_class'
    class_list = []
    for s in soup.find_all(True):
        class_list += get_class(s)
    return class_list

def get_class_count(soup):return len(list(set(get_all_class(soup))))

def is_content_list(soup):
    '判断是否为内容列表，条件为：子集是重复的相同的tag，重复次数大于5'
    children = get_children(soup)
    if len(children) > 1 and len(soup.text.strip()) > 0:
        tag_counter = Counter([c.name for c in children])
        max_tag_name,max_tag_count = tag_counter.most_common(1)[0]

        tag_similarity = max_tag_count/len(children)

        class_similarity = 1
        if get_all_class(soup):
            max_class_name,max_class_count = Counter(get_all_class(soup)).most_common(1)[0]
            class_similarity = max_class_count/len(children)

        if max_tag_count >= 5 and tag_similarity > 0.9 and class_similarity > 0.9:
            return True
    return False

def find_main_list(soup):
    '特征：文字内容多；一条数据的样式&嵌套丰富；区别于目录，都是很短的词'
    score = 0
    main_list = soup

    items = soup.find_all(True)
    for item in items:
        if is_content_list(item):
            text_count = len(item.text)
            class_count = get_class_count(item)
            text_max_lenth = max([len(i) for i in item.stripped_strings])
#             print('候选：\n',soup.name,get_class(soup),text_count,text_max_lenth,class_count)

            new_score = text_count*class_count*text_max_lenth
            if new_score > score:
                score = new_score
                main_list = item
    first_child = get_children(main_list)[0]
    print('终选：\n',main_list.name,get_class(main_list),first_child.name,get_class(first_child),'\n')
    return main_list

# Cell
def is_next_page(tag): return tag.name == 'a' and re.search(r'[后|下]一*页',tag.text)

def get_next_page_url(soup):
    next_page = soup.find(is_next_page)
    if next_page and 'href' in next_page.attrs:
        print('下一页：',next_page['href'])
        return next_page['href']
    else:
        print('未识别出下一页')
        return None

# Cell
def get_child_navigablestring(soup):
    navstr = []
    for c in soup.contents:
        if isinstance(c,NavigableString) and c.strip():
            navstr.append(c.strip())
    navstr = '&&'.join(navstr)
    return navstr

def get_data_name(soup):
    class_name = '_'.join(get_class(soup))
    return f'{soup.name}_{class_name}'

def get_data(soup):
    '列出每一项，如果为a或img标签，就获取链接和内容；如果子集含navstr，就显示文字'
    data = {}
    for c in soup.find_all(True):
        if c.name == 'a':
            if 'href' in c.attrs and c['href']:
                data[get_data_name(c)+'_url'] = c['href']
            if 'title' in c.attrs and c['title']:
                data[get_data_name(c)+'_title'] = c['title']

        if c.name == 'img':
            if 'src' in c.attrs and c['src']:
                data[get_data_name(c)+'_src'] = c['src']

        navstr = get_child_navigablestring(c)
        if navstr:
            data[get_data_name(c)+'_text'] = navstr
    return data

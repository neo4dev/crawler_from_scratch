# AUTOGENERATED! DO NOT EDIT! File to edit: 11_Proxy_Request.ipynb (unless otherwise specified).

__all__ = ['Proxy']

# Cell
import requests,json,re,random,sys,time,os
from bs4 import BeautifulSoup,Tag,NavigableString

from .utils import *

from concurrent.futures import ThreadPoolExecutor
import pandas as pd


# Cell
class Proxy():
    '一个代理器，用爬取的免费代理ip，来爬取网站'
    def __init__(self):
        self.db = {}
        self.path = './data/11_Proxy.json'
        self.debug = True

        if os.path.exists(self.path):
            with open(self.path, 'r') as f:
                self.db = json.loads(f.read())
                print('加载成功',len(self.db.keys()))
        else:
            self.update(self)

    def update(self):
        '重新爬取ip，初始化health值，赋值给`self.db`，保存在`self.path`'
        data = []
        next_page_url = 'https://www.freeip.top/api/proxy_ips?page=1'
        while next_page_url:
            if self.debug: print('start:',next_page_url)
            res = requests.get(next_page_url)
            if res.status_code == 200:
                data_list = res.json()['data']['data']
                data += data_list
                next_page_url = res.json()['data']['next_page_url']
            time.sleep(1)
        # ip list 转 dict 增加健康值
        self.db = {}
        for d in data:
            _id = d['unique_id']
            self.db[_id] = d
            self.db[_id]['health'] = 50

        self.save()

        self.validate('http://www.baidu.com/')
        self.validate('https://www.baidu.com/')

    def save(self):
        with open(self.path, 'w') as f:
            json.dump(self.db,f)
            print('更新成功',len(self.db.keys()))

    def validate(self,url,max_workers=50):
        '批量测试ip有效性'
        protocol = url.split(':')[0]
        db_with_protocol = [self.db[k] for k in self.db if self.db[k]['protocol'] == protocol]

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            executor.map(lambda ip_obj : self._get(url,ip_obj),db_with_protocol)

    def choose_healthy_ip(self,protocol):
        '根据健康度，随机选择优质ip'
        db_with_protocol = [self.db[k] for k in self.db if self.db[k]['protocol'] == protocol]
        sorted_db = sorted(db_with_protocol,
                           key = lambda item : item['health'],
                           reverse=True)
        return random.choice(sorted_db[:10])

    def update_ip_health(self,res,obj):
        '根据response，更新health'
        if res.status_code == 200:
            obj['health'] += 1
        else:
            obj['health'] = int(obj['health']/2)
        if self.debug: print(obj['ip'],'健康值变为：',obj['health'])

    def _get(self,url,ip_obj={}):
        '如果不指定ip，则自动选择`self.db`中最优的ip，访问网页，并更新health值'
        protocol = url.split(':')[0]
        if not ip_obj: ip_obj = self.choose_healthy_ip(protocol)
        ip = f"{ip_obj['protocol']}://{ip_obj['ip']}:{ip_obj['port']}"

        try:
            res = requests.get(url,
                               proxies={protocol: ip},
                               headers={'user-agent':'Mozilla/5.0'},
                               timeout=5)
        except:
            if self.debug: print(f'error: {ip}\n{sys.exc_info()}\n')
            res = requests.Response()

        self.update_ip_health(res,ip_obj)

        return res
    def get(self,url):
        '如果一个网页访问失败，会更换ip重试10次'
        try_times = 1
        while try_times < 11:
            if self.debug : print('\n',try_times,url)
            res = self._get(url)
            if res.status_code == 200:
                print('访问成功：',url)
                return res
            else:
                try_times += 1
        print('访问失败：',url)
        return res

